<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Guía del Laboratorio :: Template Tutorial</title>
    <link rel="canonical" href="https://github.com/rhcs-workshops/summit-connect-madrid-ilab/instructlab/01-implementation.html">
    <link rel="prev" href="index.html">
    <link rel="next" href="02-annex.html">
    <meta name="generator" content="Antora 3.0.0">
    <link rel="stylesheet" href="../_/css/site.css">
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://developers.redhat.com" target="_blank"><img src="../_/img/RHDLogo.svg" height="40px" alt="Red Hat Developer Program"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="https://github.com/rhcs-workshops/summit-connect-madrid-ilab">Template Tutorial</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://developers.redhat.com/ebooks/" target="_blank">Books</a>
        <a class="navbar-item" href="https://developers.redhat.com/cheatsheets/" target="_blank">Cheat Sheets</a>
        <a class="navbar-item" href="https://developers.redhat.com/events/" target="_blank">Upcoming Events</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Tutorials</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/kubernetes-tutorial/" target="_blank">Kubernetes</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/istio-tutorial/" target="_blank">Istio</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/quarkus-tutorial/" target="_blank">Quarkus</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/knative-tutorial/" target="_blank">Knative</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/tekton-tutorial/" target="_blank">Tekton</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="instructlab" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html"></a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="01-implementation.html">Guia del laboratorio</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#instalacion">1. Instalación</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#uso-basico">2. Uso básico</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#entrenamiento">3. Entrenamiento del modelo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="#interaccion">4. Modelo entrenado</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="02-annex.html">Anexo</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-annex.html#que-es-un-llm">¿Qué es un LLM?</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-annex.html#como-entrenar-llm">¿Cómo se entrenan los LLM?</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-annex.html#relacion-instructlab">¿Cómo se relaciona con InstructLab?</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">InstructLab</a></li>
    <li><a href="01-implementation.html">Guia del laboratorio</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/rhcs-workshops/summit-connect-madrid-ilab/edit/master/documentation/modules/ROOT/pages/01-implementation.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<article class="doc">
<h1 class="page">Guía del Laboratorio</h1>
<div class="sect1">
<h2 id="instalacion"><a class="anchor" href="#instalacion"></a>1. Instalación</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_requisitos_del_sistema"><a class="anchor" href="#_requisitos_del_sistema"></a>Requisitos del sistema</h3>
<div class="ulist">
<ul>
<li>
<p>Python 3.9+</p>
</li>
<li>
<p>60GB de espacio en disco</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_instalar_el_entorno"><a class="anchor" href="#_instalar_el_entorno"></a>Instalar el entorno</h3>
<div class="paragraph">
<p>Para comenzar, establecemos un entorno virtual de Python que nos permitirá interactuar con InstructLab. Luego, instalaremos InstructLab.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cd ~/instructlab
source venv/bin/activate
pip install git+https://github.com/instructlab/instructlab.git@v0.17.1</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Perfecto! Ya podemos usar InstructLab con el comando <code>ilab</code>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="uso-basico"><a class="anchor" href="#uso-basico"></a>2. Uso básico</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_inicialización"><a class="anchor" href="#_inicialización"></a>Inicialización</h3>
<div class="paragraph">
<p>Antes de usar un modelo, hay que establecer la inicialización. Durante esta fase ocurren varias cosas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se localiza una taxonomía por defecto en el sistema de archivos local.</p>
</li>
<li>
<p>Se crea un archivo de configuración (config.yaml) en el directorio actual.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El archivo <strong>config.yaml</strong> contiene los valores predeterminados que utilizaremos. Estos nos permiten ajustar el comportamiento del modelo, por ejemplo que use un número determinado de CPUs.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab config init
-&gt; Presiona enter cuando el comando pida argumentos.</code></pre>
</div>
</div>
<div class="paragraph">
<p>El resultado final de ejecutar el comando es:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">'Initialization completed successfully, you`re ready to start using ilab. Enjoy!'</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_descargar_el_modelo"><a class="anchor" href="#_descargar_el_modelo"></a>Descargar el modelo</h3>
<div class="paragraph">
<p>Con el entorno configurado, ahora podemos descargar un modelo comprimido y optimizado al directorio local para ser utilizado como un servidor.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab model download --repository instructlab/granite-7b-lab-GGUF --filename=granite-7b-lab-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>El comando <code>ilab model download</code> descarga el modelo Granite 7b Lab desde los repositorios de HuggingFace.</p>
</div>
</div>
<div class="sect2">
<h3 id="_servir_el_modelo"><a class="anchor" href="#_servir_el_modelo"></a>Servir el modelo</h3>
<div class="paragraph">
<p>Ahora debemos servir el modelo para poder interactuar con él de forma muy parecida a como haríamos llamadas a una API.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab model serve --model-path models/granite-7b-lab-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Genial! Con el modelo ya servido, estamos listos para probar el LLM.</p>
</div>
</div>
<div class="sect2">
<h3 id="_chatear_con_el_modelo"><a class="anchor" href="#_chatear_con_el_modelo"></a>Chatear con el modelo</h3>
<div class="paragraph">
<p>Vamos a dejar el modelo sirviendose en el terminal donde hemos trabajado y abriremos una nueva pestaña del terminal. Volveremos a activar el entorno virtual de Python.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cd ~/instructlab
source venv/bin/activate</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ya dentro del entorno, podemos iniciar una sesión de chat con el comando ilab chat:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab model chat -m models/granite-7b-lab-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>En tu terminal debería aparecer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">╭───────────────────────────────────────────────────────────────────────────╮
│ Welcome to InstructLab Chat w/ MODELS/GRANITE-7B-LAB-Q4_K_M.GGUF
╰───────────────────────────────────────────────────────────────────────────╯
&gt;&gt;&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Tenemos todo listo para hacerle preguntas a nuestro LLM. Prueba a escribir una pregunta: ¿Qué es Openshift en 20 palabras o menos?</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">¿Qué es Openshift en 20 palabras o menos?</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Genial! Parece que el modelo funciona y es capaz de generar una respuesta a nuestras preguntas.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="entrenamiento"><a class="anchor" href="#entrenamiento"></a>3. Entrenamiento del Modelo</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_preparar_el_entorno_para_el_entrenamiento"><a class="anchor" href="#_preparar_el_entorno_para_el_entrenamiento"></a>Preparar el entorno para el entrenamiento</h3>
<div class="paragraph">
<p>Vamos a probar con otra pregunta como:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">¿Qué es InstructLab?</code></pre>
</div>
</div>
<div class="paragraph">
<p>El modelo debería ser capaz de generar una respuesta que parece correcta, pero no lo es y se aleja mucho de la realidad.
Estos errores suelen denominarse «alucinaciones». La alineación de modelos (como la que haremos ahora) es una forma de mejorar las respuestas de un modelo y evitar alucinaciones.</p>
</div>
<div class="paragraph">
<p>Para solucionar esto, nos centraremos en añadir nuevo conocimiento al modelo para que sepa más sobre InstructLab. ¡Manos a la obra!</p>
</div>
<div class="paragraph">
<p>Primero vamos a terminar la sesión de chat con el modelo. Escribe 'exit'.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">exit</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora vamos a mejorar el modelo modificando su taxonomía.</p>
</div>
</div>
<div class="sect2">
<h3 id="_entender_la_taxonomía"><a class="anchor" href="#_entender_la_taxonomía"></a>Entender la taxonomía</h3>
<div class="paragraph">
<p>¿Te has preguntado por qué InstructLab se llama así?</p>
</div>
<div class="paragraph">
<p>El método LAB se basa en taxonomías.
InstructLab facilita el proceso de ajuste y mejora de los modelos mediante la recopilación de dos tipos de datos: conocimientos y habilidades.
La comunidad open-source sube aportaciones y se recogen en una taxonomía de archivos YAML. Esta se utiliza en el proceso de generación de datos sintéticos.</p>
</div>
<div class="paragraph">
<p>Echémosle un ojo a la taxonomía actual.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cd ~/instructlab
tree taxonomy/ | head</code></pre>
</div>
</div>
<div class="paragraph">
<p>Podemos ver que la taxonomía recoge conocimiento sobre artes, ingeniería, geografía&#8230;&#8203; Vamos a crear un directorio en el que insertar el conocimiento sobre InstructLab.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">mkdir -p ~/instructlab/taxonomy/knowledge/instructlab/overview</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora incluiremos un archivo <strong>qna.yaml</strong>. Este contiene un cojunto de preguntas y respuestas sobre lo que queremos que aprenda el modelo.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cp -av ~/files/qna.yaml ~/instructlab/taxonomy/knowledge/instructlab/overview</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para comprobar que hemos copiado el archivo correcto, prueba el siguiente comando:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">head ~/instructlab/taxonomy/knowledge/instructlab/overview/qna.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Si todo ha ido bien, deberías poder ver una pregunta y una respuesta. Con InstructLab, puedes comprobar que la estructura de la taxonomía es correcta con un comando.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab taxonomy diff</code></pre>
</div>
</div>
<div class="paragraph">
<p>Deberías obtener lo siguiente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">Taxonomy in /taxonomy/ is valid :)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Hasta aquí todo bien. ¡Toca a pasar a la parte más divertida!</p>
</div>
<div class="paragraph">
<p>Vamos a utilizar la taxonomía para que el LLM genere más ejemplos. Esto puede tardar un poco y depende del número de instrucciones que queramos generar. Para este workshop, pediremos que genere 5 muestras.</p>
</div>
<div class="paragraph">
<p>Primero, necesitamos parar el servidor. En la pestaña del terminal en la que se está ejecutando, pulsa <code>CTRL</code>+<code>C</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">INFO 2024-05-06 18:41:08,496 server.py:197 After application startup complete see http://127.0.0.1:8000/docs for API.
^C
Aborted!</code></pre>
</div>
</div>
<div class="paragraph">
<p>A continuación, usaremos Merlinite como modelo maestro a efectos de nuestra generación de datos sintéticos:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cd ~/instructlab
cp ~/.cache/instructlab/models/merlinite-7b-lab-Q4_K_M.gguf  ~/instructlab/models
ilab model serve --model-path models/merlinite-7b-lab-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora, volvemos a nuestra segunda pestaña del terminal y ejecutamos este comando:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab data generate --num-instructions 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Y ahora sucede la magia! InstrucLab tardará unos minutos en generar los ejemplos.</p>
</div>
<div class="paragraph">
<p>Realmente generar 5 ejemplos no es suficiente para impactar en el despempeño de un modelo. Debido a las limitaciones de tiempo, el objetivo es simplemente mostrarte el proceso utilizando comandos reales. Lo normal sería generar 100 o incluso 1000 datos adicionales. Red Hat proporciona herramientas como RHEL AI y OpenShift AI para entrenar LLMs de producción de forma efectiva.</p>
</div>
<div class="paragraph">
<p>Una vez que haya terminado, ¡échale un vistazo a las preguntas y respuestas que ha generado en el terminal! El siguiente paso es entrenar el modelo con la habilidad actualizada. Esto se realiza con el comando <code>ilab train</code>. Sin embargo, no vamos a realizar el entrenamiento debido a limitaciones de tiempo.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="interaccion"><a class="anchor" href="#interaccion"></a>4. Modelo entrenado</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ya estamos listos para servir el nuevo modelo. Por cuestión de tiempo, serviremos un modelo preentrenado con 100 ejemplos en vez de 5, usando exactamente el mismo proceso que antes.</p>
</div>
<div class="paragraph">
<p>Vamos a la primera pestaña del terminal y dejamos de servir el modelo Merlinite usando <code>CTRL</code>+<code>C</code>. Luego, servimos el modelo preentrenado:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab model serve --model-path models/ggml-ilab-pretrained-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>Volvemos a la segunda pestaña del terminal e iniciamos el chat con el LLM.</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ilab model chat --greedy-mode -m models/ggml-ilab-pretrained-Q4_K_M.gguf</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Llega la hora de la verdad! Prueba a preguntar al LLM sobre InstructLab:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">¿Qué es Instructlab?</code></pre>
</div>
</div>
<div class="paragraph">
<p>¡Yuju! La respuesta debería ser mucho mejor que la última vez. El LLM debe ser capaz de describir a la perfección el proyecto InstructLab.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusión"><a class="anchor" href="#_conclusión"></a>Conclusión</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>¡Laboratorio terminado con éxito!</strong> Esperamos que hayas disfrutado probando de primera mano el potencial de InstructLab. Como pequeño repaso, has conseguido lo siguiente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Chatear con un LLM</p>
</li>
<li>
<p>Crear ejemplos con un LLM para entrenar el modelo</p>
</li>
<li>
<p>Comprobar el desempeño del modelo entrenado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Gracias por haber dedicado tu esfuerzo y tiempo en a aprender más sobre inteligencia articial y LLMs. Para más información sobre InstructLab, ¡echa un ojo a la comunidad en Github! <a href="https://github.com/instructlab" class="bare">https://github.com/instructlab</a></p>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html">InstructLab</a></span>
  <span class="next"><a href="02-annex.html">Anexo</a></span>
</nav>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a class="rhd-logo" href="https://developers.redhat.com" target="_blank"></div>
</footer>
<script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
